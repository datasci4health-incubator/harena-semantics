{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_1 = 'especialista_sepsis_train_mode'\n",
    "tsv_2 = 'novato_sepsis_train_mode'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_embeddings_file_1 = 'tsv_files/' + tsv_1 + '/last_embedding.tsv'\n",
    "labels_file_1 = 'tsv_files/' + tsv_1 + '/labels.tsv'\n",
    "last_embeddings_file_2 = 'tsv_files/' + tsv_2 + '/last_embedding.tsv'\n",
    "labels_file_2 = 'tsv_files/' + tsv_2 + '/labels.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tsv_files/especialista_sepsis_train_mode/last_embedding.tsv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_embeddings_file_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv1_embeddings_read = pd.read_csv(last_embeddings_file_1, sep='\\t')\n",
    "tsv1_labels_read = pd.read_csv(labels_file_1, sep='\\t')\n",
    "\n",
    "tsv2_embeddings_read = pd.read_csv(last_embeddings_file_2, sep='\\t')\n",
    "tsv2_labels_read = pd.read_csv(labels_file_2, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3216"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsv1_embeddings_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tsv2_embeddings_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_1 = []\n",
    "unique_embeddings_1 = []\n",
    "\n",
    "for ((index, row), label) in zip(tsv1_embeddings_read.iterrows(), tsv1_labels_read['labels']):\n",
    "    if label not in unique_labels_1:\n",
    "        unique_labels_1.append(label)\n",
    "        unique_embeddings_1.append(row)\n",
    "        \n",
    "unique_labels_2 = []\n",
    "unique_embeddings_2 = []\n",
    "        \n",
    "for ((index, row), label) in zip(tsv2_embeddings_read.iterrows(), tsv2_labels_read['labels']):\n",
    "    if label not in unique_labels_2:\n",
    "        unique_labels_2.append(label)\n",
    "        unique_embeddings_2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR = 'src/embeddings/tsv_files/' + result_file + '/'\n",
    "\n",
    "if not os.path.exists(PATH_DIR):\n",
    "    os.mkdir(PATH_DIR)\n",
    "\n",
    "with open(PATH_DIR + 'last_embedding.tsv', \"w\") as f:\n",
    "    print(column_index, file=f)\n",
    "    for e in last_embeddings:\n",
    "        print (e, file=f)\n",
    "\n",
    "\n",
    "        with open(PATH_DIR + \"labels.tsv\", \"w\") as labels_file:\n",
    "            print('labels', file=labels_file)\n",
    "            for token in tokenized_input:\n",
    "                print(token, file=labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              -0.169858\n",
       "1              -0.128899\n",
       "2              -0.326711\n",
       "3              -0.184527\n",
       "4               0.127411\n",
       "                  ...   \n",
       "764             0.409614\n",
       "765            -0.334236\n",
       "766             0.117061\n",
       "767            -0.434799\n",
       "Unnamed: 768         NaN\n",
       "Name: 0, Length: 769, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_embeddings_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0.141624\n",
       "1              -0.419996\n",
       "2              -0.638480\n",
       "3               0.008275\n",
       "4               0.197818\n",
       "                  ...   \n",
       "764             0.801773\n",
       "765            -0.415054\n",
       "766             0.667141\n",
       "767            -0.149225\n",
       "Unnamed: 768         NaN\n",
       "Name: 0, Length: 769, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_embeddings_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def pytorch_cos_sim(a: Tensor, b: Tensor):\n",
    "    print('11111111111')\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    This function can be used as a faster replacement for 1-scipy.spatial.distance.cdist(a,b)\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    print(a.norm(dim=1))\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111111111\n",
      "tensor([nan])\n",
      "result  tensor([[nan]])\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from pandas import DataFrame\n",
    "\n",
    "for (token_embedding_novato, label_novato) in zip(unique_embeddings_2, unique_labels_2):\n",
    "#     print(label_novato)\n",
    "    try:\n",
    "        term_label_especialista = unique_labels_1.index(label_novato)\n",
    "#         term_label_especialista = unique_labels_1.index('African')\n",
    "#         print('especialista ',term_label_especialista)\n",
    "#         print('especialista',unique_labels_1[term_label_especialista])\n",
    "#         print(unique_embeddings_1[term_label_especialista])\n",
    "        token_embedding_especialista = unique_embeddings_1[term_label_especialista]\n",
    "\n",
    "        tensor_especialista = torch.tensor(token_embedding_especialista)\n",
    "        tensor_novato = torch.tensor(token_embedding_novato)\n",
    "#         print(tensor_especialista)\n",
    "#         print(tensor_novato)\n",
    "#         print('aqio')\n",
    "        result = pytorch_cos_sim(tensor_especialista, tensor_novato)\n",
    "        print('result ',result)\n",
    "    #     print('especialista', token_embedding_especialista)\n",
    "    #     print('aluno', token_embedding_novato)\n",
    "#         print(token_embedding_especialista)\n",
    "        df = DataFrame({\"col1\": token_embedding_especialista,\n",
    "                        \"col2\": token_embedding_novato })\n",
    "#         print(type(df[\"col1\"]))\n",
    "#         print('cosine result ', cosine(df[\"col1\"], df[\"col2\"]))\n",
    "        break\n",
    "    except Exception as e:\n",
    "        i = 0\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_novato' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-d7e8e0939412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# token_embedding_especialista\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_cos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_especialista\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_novato\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor_novato' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# token_embedding_especialista\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.3472e-01,  2.3170e-02, -4.0187e-01, -3.3031e-01,  3.1913e-01,\n",
       "        -1.4690e-01,  6.3250e-01, -8.3803e-01, -7.1508e-01, -6.4339e-01,\n",
       "        -4.8003e-01,  5.7238e-01, -4.1638e-01, -1.0745e-01, -9.4953e-01,\n",
       "         1.6062e-01, -9.7008e-01, -9.5650e-01,  5.5116e-01,  3.2915e-01,\n",
       "        -2.3029e-01, -3.5626e-01, -1.2439e-01,  4.5377e-04,  1.4112e-01,\n",
       "        -1.6687e-01,  3.6463e-01,  6.3891e-02,  8.9786e-01,  2.9568e-01,\n",
       "        -3.1111e-01, -8.2465e-01,  1.0484e+00,  4.6868e-01,  1.0749e+00,\n",
       "         1.0382e-01, -1.0551e-01, -2.5136e-02, -3.0725e-01,  3.0086e-01,\n",
       "         7.6471e-01,  8.5248e-01,  2.2365e+00,  4.1145e-01, -4.1970e-01,\n",
       "        -5.6617e-02, -1.9882e-01,  1.0688e-01,  4.0109e-01,  1.2980e-01,\n",
       "         6.4186e-01,  3.4333e-01,  3.6581e-01,  1.2139e-01,  3.9199e-01,\n",
       "        -1.2808e+00, -8.3080e-01, -2.0000e-01, -3.1272e-01,  2.3809e-01,\n",
       "         7.9535e-01,  2.1832e-01, -1.3028e+00,  4.3918e-03, -1.6558e-01,\n",
       "        -6.9515e-01, -2.4753e-01,  5.0175e-01, -6.1234e-02, -2.8959e-01,\n",
       "        -5.7991e-01, -8.2910e-01,  8.0264e-02, -1.3826e-01,  3.6950e-02,\n",
       "        -1.2801e-01,  2.2047e-02, -1.8915e-01,  7.5575e-01, -1.6564e-01,\n",
       "         1.2237e-01,  1.1829e-01, -1.5333e-01, -2.3651e-01,  2.6934e-01,\n",
       "         2.4986e-01, -1.1135e-01,  5.7724e-01, -6.6188e-01, -6.4051e-01,\n",
       "        -3.3555e-01, -9.4254e-02, -1.5934e-01, -3.7672e-01,  7.6452e-02,\n",
       "         7.6279e-01,  1.8785e-01,  1.6230e-01, -5.6000e-01,  4.3322e-01,\n",
       "         1.8546e-01,  1.9813e-01,  2.5427e-01,  3.3689e-01,  5.3816e-01,\n",
       "        -9.9315e-02, -8.0981e-01,  7.1483e-01,  3.1207e-01,  8.0301e-01,\n",
       "        -5.9620e-01,  2.4264e-01,  9.3427e-01, -7.0364e-01,  6.8713e-01,\n",
       "         2.9299e-01,  3.2425e-01,  1.0307e+00, -1.4205e-01,  5.7150e-01,\n",
       "         6.3218e-01, -3.5885e-01,  2.9934e-01,  6.6814e-01, -5.9381e-01,\n",
       "        -2.2370e-01,  9.8607e-01,  1.1761e-01,  1.3778e+00, -1.6156e-01,\n",
       "         3.4533e-02,  6.0878e-01, -1.1007e+00, -3.6699e-01,  5.1911e-01,\n",
       "        -2.4840e-01, -1.2552e+00,  1.2153e-01, -1.1200e+00, -6.9587e-02,\n",
       "         3.7006e-01, -4.6970e-01, -4.9103e-01, -3.2527e-02, -2.5982e-01,\n",
       "        -1.6973e-01, -4.8924e-02,  1.8326e-01, -4.6821e-01,  5.2519e-01,\n",
       "        -8.2480e-01, -1.4009e+00, -1.8301e-01, -1.1837e+00, -1.2243e-01,\n",
       "        -1.8198e-01,  7.2007e-01, -1.3874e-01,  1.2592e+00, -4.1781e-01,\n",
       "        -6.9772e-01, -5.9977e-01, -1.0288e+00, -2.6433e-02, -5.3974e-01,\n",
       "         4.7119e-01,  1.1047e-01, -2.5834e-01, -1.3222e-01,  9.8701e-01,\n",
       "         3.5961e-01, -8.5096e-01,  3.2224e-02,  5.1742e-01,  7.8075e-01,\n",
       "        -1.6769e-01,  4.4578e-01, -6.4174e-01, -5.4363e-01, -2.4669e-01,\n",
       "        -5.0221e-01, -3.8372e-01, -2.4623e-01,  8.7681e-02, -2.0557e-01,\n",
       "        -8.0164e-01, -6.1207e-01,  4.6944e-01, -1.1716e+00,  1.9299e-03,\n",
       "        -5.2494e-01,  2.1869e-01, -8.4267e-01, -2.3464e-01,  4.5625e-01,\n",
       "        -2.2822e-01,  8.0310e-01, -2.4672e-01, -2.4837e-01,  1.5377e-01,\n",
       "         3.8583e-01,  1.5970e-01, -2.3197e-01,  4.9195e-01, -1.0709e+00,\n",
       "        -5.2955e-01,  3.9969e-01, -3.2257e-01,  1.1301e-01, -3.5344e-01,\n",
       "        -9.7419e-01, -9.5740e-01,  4.4393e-01, -4.7116e-02, -4.5783e-01,\n",
       "        -1.2417e+00, -8.9522e-01, -1.1217e-01,  5.8580e-02, -2.7519e-01,\n",
       "        -5.6861e-02,  2.8455e-01,  1.3126e-02,  1.2050e+00,  2.1847e-01,\n",
       "        -3.4364e-02, -6.7499e-01,  1.6007e-01,  5.1163e-01, -4.3200e-01,\n",
       "         3.5271e-01, -2.5493e-01, -3.3363e-01,  5.8662e-03, -6.0718e-01,\n",
       "         7.4928e-02,  3.6284e-01,  3.7522e-01,  9.1275e-01,  4.4627e-01,\n",
       "        -1.2838e-01, -5.5237e-01,  1.3515e+00, -5.3913e-02, -7.3198e-02,\n",
       "         7.4140e-02, -2.5370e-01, -6.4853e-01, -4.8412e-01, -4.3912e-01,\n",
       "         1.2246e+00,  5.4629e-01,  1.6587e-01, -8.0994e-01,  2.0068e+00,\n",
       "        -1.0835e-01,  1.7738e-01,  1.9430e-01, -9.4624e-02, -1.6365e-01,\n",
       "         4.6850e-01, -4.1803e-02, -4.7890e-01, -4.7039e-01, -3.0776e-01,\n",
       "        -2.6407e-02, -6.4927e-02,  1.9683e-01, -3.7423e-01,  3.5309e-01,\n",
       "        -4.8058e-01,  1.7708e-01, -1.1643e+00, -7.3785e-01, -7.7450e-01,\n",
       "        -3.4660e-01, -1.3300e-03, -3.0353e-01,  3.7808e-01,  2.9386e-01,\n",
       "        -4.7506e-02,  1.7584e+00, -7.8043e-01,  4.7967e-01,  5.0728e-01,\n",
       "         5.9934e-01, -5.8575e-02,  4.7823e-01, -8.3433e-01, -6.5482e-02,\n",
       "        -5.5514e-02, -6.1449e-01, -2.2981e-01, -3.6901e-01, -1.4348e-01,\n",
       "        -2.2600e-03, -1.1080e+00, -7.8414e-01, -1.8592e-01, -1.4554e+00,\n",
       "        -7.0859e-01, -5.6313e-02, -2.7755e-01, -6.0718e-01, -1.1365e-01,\n",
       "        -5.5183e-01,  1.4564e+00, -9.6798e-01, -5.7241e-01, -6.4972e-02,\n",
       "        -8.7118e-01,  5.6165e-01,  3.7053e-01, -2.6597e-02,  2.2005e-03,\n",
       "         2.7926e-01,  3.8231e-01,  7.6749e-01, -8.5211e-01,  4.1959e-01,\n",
       "         5.7801e-01,  4.8554e-01,  6.6944e-02,  7.2035e-01,  6.1317e-01,\n",
       "         2.9647e-01, -3.7644e-02,  2.0052e-01, -1.3257e+00, -4.5969e-01,\n",
       "         8.7242e-01,  1.1673e+00, -5.1976e-01, -4.5116e-01, -2.8094e-01,\n",
       "        -1.3024e+00, -7.0959e-01, -6.1732e-01, -4.5307e-01,  3.0092e-01,\n",
       "        -5.7318e-01,  2.0746e-02, -4.6487e-01, -7.1360e-01, -3.9993e-01,\n",
       "         2.8256e-01, -2.2089e-01,  1.1365e-01, -1.0286e+00,  6.2395e-02,\n",
       "        -9.8589e-02, -8.0216e-01, -6.3973e-01,  5.9919e-01, -1.4291e-01,\n",
       "         4.4950e-01,  3.9074e-01,  6.6507e-01,  3.3831e-01, -7.1142e-01,\n",
       "         1.7372e-02,  7.6478e-01,  5.0691e-01,  4.9334e-01,  1.2889e-01,\n",
       "        -5.7445e-03, -9.1053e-01, -6.7318e-01,  4.2072e-01, -2.6640e-01,\n",
       "         3.5394e-01,  2.2517e-01, -4.6508e-01, -4.7599e-01, -4.5343e-02,\n",
       "        -4.6795e-01,  9.2466e-03,  1.2564e-01, -2.5030e-01, -5.4044e-01,\n",
       "        -6.2845e-01, -3.8234e-01,  3.2391e-01, -1.5171e-01, -1.0050e-01,\n",
       "         2.7320e-01,  2.4085e-01,  1.1759e+00, -3.6792e-01, -2.1388e-01,\n",
       "        -4.0700e-02, -4.7872e-01, -5.4830e-01, -2.5241e-01,  5.0223e-01,\n",
       "         2.4191e-01,  3.0933e-01,  1.0886e+00, -1.1495e-01, -3.9624e-01,\n",
       "        -6.2165e-01,  9.6615e-02, -2.6201e-01,  7.7867e-01, -1.2317e+00,\n",
       "         2.4819e-01,  8.5975e-04, -4.9916e-01, -3.7197e-01,  3.6531e-01,\n",
       "        -1.7759e+00, -8.8138e-01, -3.3942e-01,  2.5245e-01,  3.5843e-03,\n",
       "         1.6940e-01, -6.0352e-01,  4.9087e-01,  1.2842e-01, -1.1077e-01,\n",
       "         1.8721e-01, -1.5264e-01, -1.4280e-01, -8.7552e-01, -3.9654e-01,\n",
       "        -9.5608e-02,  7.1445e-02, -1.1791e-02, -6.8494e-01,  9.0615e-01,\n",
       "         2.4417e-02,  9.9468e-01, -3.5537e-01, -1.1332e+00, -1.0920e+00,\n",
       "         5.5816e-01,  1.2798e+00,  6.9924e-01,  5.3251e-01, -9.8802e-02,\n",
       "        -5.2357e-01, -7.3220e-01,  4.9325e-01,  3.0488e-02, -8.1561e-02,\n",
       "         4.2714e-01,  6.1519e-01,  7.0934e-01,  2.8850e-02, -1.3472e+00,\n",
       "         5.2356e-01,  8.7060e-01,  6.2293e-01, -6.1778e-01, -6.3002e-01,\n",
       "         1.5753e-02,  1.4625e-01,  6.4742e-02, -5.9888e-01, -7.3851e-01,\n",
       "         6.3589e-02,  1.0644e-01, -3.9792e-01,  1.8363e-01,  1.8548e-01,\n",
       "        -2.2249e-02,  4.1214e-01,  1.1885e+00,  5.2618e-01,  1.3752e+00,\n",
       "        -1.5035e-01,  1.3095e+00,  6.2423e-01,  2.1986e-01,  8.6279e-02,\n",
       "         9.9178e-01, -1.1477e-01,  2.8446e-02, -2.8005e-01, -6.9882e-01,\n",
       "        -5.4865e-01,  9.4400e-02, -9.6669e-01,  4.4092e-01, -1.1436e-01,\n",
       "         4.4147e-01, -6.2361e-01,  7.2688e-01,  1.1000e+00,  6.8071e-01,\n",
       "         2.1907e-01, -2.9088e-01, -5.0183e-01,  6.4379e-01, -1.3455e-01,\n",
       "        -8.2231e-01,  2.0504e-01, -5.6330e-01, -2.5004e-01, -4.1817e-01,\n",
       "        -4.1759e-01,  2.3983e-01, -2.4535e-01, -1.0461e-01,  4.9953e-02,\n",
       "         1.1911e+00, -1.2621e+00,  7.5443e-02, -7.3192e-01,  9.3780e-02,\n",
       "        -8.6070e-02, -3.8964e-01,  7.3025e-01, -4.3354e-01, -1.0623e-01,\n",
       "        -4.0397e-01,  8.3926e-01,  1.3571e+00, -5.0094e-01,  5.2365e-01,\n",
       "        -3.4098e-01,  3.4099e-01, -5.1882e-01, -5.5448e-01, -6.1107e-01,\n",
       "        -2.6618e-02,  9.9873e-01,  2.6799e-01, -8.3856e-02,  5.3880e-01,\n",
       "        -3.3111e-01,  4.4921e-01,  4.2355e-01,  4.8365e-01,  4.7062e-01,\n",
       "        -6.0999e-01, -1.8357e-02, -1.0705e+00, -7.3800e-01,  1.8769e-01,\n",
       "         6.9108e-01,  1.1249e+00,  9.3336e-02, -4.0074e-01, -3.6551e-01,\n",
       "         9.3075e-01,  6.3125e-01,  5.8648e-01,  5.3779e-01, -1.8649e-01,\n",
       "        -7.0557e-02, -3.3871e-01, -9.8564e-01,  1.1239e-02,  5.2551e-01,\n",
       "         5.3284e-01, -5.2891e-01, -6.1683e+00, -9.2355e-03,  3.9895e-01,\n",
       "        -2.2653e-01,  1.9450e-01, -3.7146e-01, -4.0959e-01, -9.5930e-01,\n",
       "        -7.4767e-01,  4.2983e-01,  7.5314e-01,  1.5315e-01,  2.9376e-01,\n",
       "         6.7060e-01,  4.2323e-01,  1.5152e-01,  6.6376e-01,  3.6775e-01,\n",
       "        -3.5092e-01, -4.5781e-01, -2.0627e-01, -5.6732e-02, -1.6411e-01,\n",
       "         5.0492e-01,  7.5175e-01, -3.2576e-01,  1.4875e-01,  1.6893e-01,\n",
       "         4.4111e-01, -4.0904e-01, -7.0002e-02,  4.7416e-02,  5.4089e-01,\n",
       "        -1.3489e-01,  9.7131e-02, -9.5298e-01,  5.7303e-02, -4.0289e-02,\n",
       "        -8.7448e-01,  1.6663e-01, -2.9453e-01, -4.4736e-03,  1.1915e-01,\n",
       "        -1.1502e-01,  2.3122e-02,  3.6847e-02,  8.3718e-02, -7.4972e-01,\n",
       "        -1.6789e-01,  1.1705e+00, -8.5039e-01,  1.8968e-01,  1.7012e-01,\n",
       "        -6.9947e-01, -1.2568e+00, -4.7178e-01, -2.9370e-01,  1.3659e+00,\n",
       "         8.5737e-01,  3.2815e-01,  2.4601e-02, -9.5975e-02,  1.0171e+00,\n",
       "        -1.1542e-01,  2.1154e-01, -3.4097e-01,  3.7854e-01,  1.5464e-01,\n",
       "         3.1558e-01,  9.0413e-02, -3.6885e-01, -4.2138e-01, -6.2953e-01,\n",
       "         3.4107e-01,  1.1588e+00,  3.6817e-02,  7.7779e-02, -2.4510e-01,\n",
       "         3.2004e-01,  1.8493e-01,  1.2441e-02,  5.9023e-01, -8.2380e-02,\n",
       "        -2.8859e-01,  1.1795e-01, -9.3972e-01,  2.9966e-01,  3.7237e-01,\n",
       "        -7.1009e-02,  7.9984e-01,  3.1746e-01, -3.9524e-01, -1.1294e-01,\n",
       "         1.4212e-02,  2.5737e-01,  1.1341e-01, -1.1829e+00,  7.6206e-01,\n",
       "         1.0147e+00,  4.6959e-01,  1.5294e-01,  8.4008e-01,  2.9412e-01,\n",
       "         3.2675e-01, -5.6262e-01, -1.9594e-01,  2.3536e-01,  4.6202e-01,\n",
       "         1.0211e+00,  2.3025e-01,  2.7395e-01, -6.5784e-01,  9.0933e-01,\n",
       "         6.4240e-01, -3.3255e-01,  1.1740e+00,  6.2115e-01, -2.2802e-01,\n",
       "         3.2475e-01, -3.3970e-01,  8.5812e-01,  2.9890e-01, -2.9496e-01,\n",
       "        -1.1450e-01, -3.3838e-01,  2.3925e-01, -1.3547e-01, -3.3855e-02,\n",
       "         5.0942e-01,  7.0454e-01,  6.6688e-01,  5.8680e-01,  5.1329e-01,\n",
       "         3.2631e-01,  3.9683e-01,  6.5285e-01,  4.4017e-01,  2.1196e-01,\n",
       "         7.4342e-03,  2.5561e-01,  4.0521e-01,  2.3481e-01,  4.6489e-01,\n",
       "         1.0826e-01, -2.6253e-01,  3.1257e-01,  1.6812e-01, -6.6085e-01,\n",
       "        -5.1316e-01,  7.9100e-01,  5.6469e-01, -6.9589e-01,  3.6808e-01,\n",
       "         2.8831e-01,  3.6710e-01, -6.1438e-01,  1.8043e-01, -7.7438e-01,\n",
       "        -5.1413e-01, -3.3541e-01,  5.7356e-01, -4.2335e-01,  1.2196e-01,\n",
       "        -5.3126e-03, -1.0196e+00, -1.6782e-01,  1.4650e-01, -6.4701e-01,\n",
       "        -2.6117e-01,  7.7958e-01,  9.9634e-02,  1.1909e-01,  3.2938e-01,\n",
       "        -1.3206e-01, -5.0031e-01, -1.4173e+00,  5.2095e-01, -4.5228e-02,\n",
       "         8.3159e-01, -2.3199e-01,  2.5109e-01, -1.0501e+00,  3.0357e-01,\n",
       "        -1.5176e-01,  2.9459e-01,  1.3208e-01, -5.5438e-01, -2.1147e-01,\n",
       "        -1.9359e-01, -8.0830e-01,  2.1008e-01, -3.6455e-01, -1.1996e-01,\n",
       "         3.6064e-01, -5.7324e-01, -3.4659e-01,  2.7557e-01,  1.4547e+00,\n",
       "        -8.1718e-02,  7.2144e-01,  4.1670e-02, -2.4501e-01,  9.3026e-01,\n",
       "         2.8884e-01, -1.2527e+00, -8.0746e-01, -2.9336e-01,  3.2059e-01,\n",
       "         6.4837e-01,  5.4725e-01, -1.0492e-01,         nan])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DIR = 'src/embeddings/tsv_files/' + result_file + '/'\n",
    "\n",
    "        if not os.path.exists(PATH_DIR):\n",
    "            os.mkdir(PATH_DIR)\n",
    "\n",
    "        with open(PATH_DIR + 'last_embedding.tsv', \"w\") as f:\n",
    "            print(column_index, file=f)\n",
    "            for e in last_embeddings:\n",
    "                print (e, file=f)\n",
    "\n",
    "\n",
    "        with open(PATH_DIR + \"labels.tsv\", \"w\") as labels_file:\n",
    "            print('labels', file=labels_file)\n",
    "            for token in tokenized_input:\n",
    "                print(token, file=labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              -0.169858\n",
      "1              -0.128899\n",
      "2              -0.326711\n",
      "3              -0.184527\n",
      "4               0.127411\n",
      "                  ...   \n",
      "764             0.409614\n",
      "765            -0.334236\n",
      "766             0.117061\n",
      "767            -0.434799\n",
      "Unnamed: 768         NaN\n",
      "Name: 0, Length: 769, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(unique_embeddings_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               0.141624\n",
      "1              -0.419996\n",
      "2              -0.638480\n",
      "3               0.008275\n",
      "4               0.197818\n",
      "                  ...   \n",
      "764             0.801773\n",
      "765            -0.415054\n",
      "766             0.667141\n",
      "767            -0.149225\n",
      "Unnamed: 768         NaN\n",
      "Name: 0, Length: 769, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(unique_embeddings_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
