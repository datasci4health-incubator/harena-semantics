{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusteriza uma sentença e busca o BERT-cluster mais próximo do cluster da sentença"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abre arquivo tsv e pega os cluster-embeddings centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 768)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('clustering-results/biobert-base/6000clusters.tsv', sep='\\t',header=None)\n",
    "\n",
    "original_clusters_centroids = df.to_numpy()\n",
    "clusters_centroids = original_clusters_centroids[:,1:769]\n",
    "clusters_centroids.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegar os embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "   \n",
    "    hidden_states = get_hidden_states(bert_model, tokenizer, text)\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(bert_model, tokenizer, text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('../models/biobert', output_hidden_states = True)\n",
    "tokenizer = BertTokenizer.from_pretrained('../models/biobert', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 13, 768])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"A 58-year-old African-American woman presents to the ER with episodic pressing/burning anterior chest pain that began two days earlier for the first time in her life. The pain started while she was walking, radiates to the back, and is accompanied by nausea, diaphoresis and mild dyspnea, but is not increased on inspiration. The latest episode of pain ended half an hour prior to her arrival. She is known to have hypertension and obesity. She denies smoking, diabetes, hypercholesterolemia, or a family history of heart disease. She currently takes no medications. Physical examination is normal. The EKG shows nonspecific changes.\"\n",
    "# sentence = 'The true incidence of sepsis in any given country is unknown. The reported incidence is dependent on the specific definition used, the infecting organism, the reporting mechanism (such as the use of the International Classification of Diseases-9 coding systems) and the requirement for either organ support or intensive care. These factors result in marked differences between estimates and discrete geographical locations. Most data describing the incidence of sepsis are from high-income countries, where 2.8 million deaths per year are attributable to sepsis. In 2001, Angus and colleagues reported in, the USA the, that incidence of severe sepsis was more than 750 000 cases per annum (300 cases per 100 000 population), equivalent to 2.26 cases per 100 hospital discharges. In the UK, the reported prevalence of sepsis in ICU-derived cohorts is 27% of all ICU admissions, whereas the prevalence is 12% in the USA. 14 This difference could partly be explained by the sub stantially greater numbers of ICU beds available in the USA than in the UK, and thus the differing triage patterns and admission criteria. It is also possible that, in institutions where clinical staff are trained in sepsis recognition, the previous use of the less-specific SIRS criteria could have led to an over-reporting of sepsis cases.'\n",
    "# sentence = \"Overall, however, there is probably a substantial under-reporting of the incidence of sepsis and with an ageing population, the incidence will continue to increase. This pattern might be further accentuated by campaigns to increase the awareness of and screening for the condition. Except for maternal and neonatal sepsis, the condition is usually considerably under-reported in the global burden of disease statistics. The true scale of the problem is probably much higher than what has been reported. Data suggest that sepsis contributes to between a third and a half of all in-hospital deaths in the USA. Although these data represent the incidence of sepsis in high-resource countries, most deaths due to sepsis happen in low-resource countries, where the exact incidence of sepsis is difficult to accurately estimate. The available literature suggests that an estimated 90% of worldwide deaths from chest infections occur in low-resource settings; about 70% of the 9 million deaths due to chest infections in neonates and infants are associated with sepsis, and most cases occur in Asia and Africa. Sepsis can be a terminal event in patients who are already dying from other causes (eg, terminal cancer). This fact is especially important to remember in the context of an increased number of admissions of old and frail patients in hospital wards and ICUs, and when evaluating our expectations on to what extent mortality rates from sepsis can be reduced. It is very likely that a baseline mortality from sepsis is part of the nature of the syndrome itself, and in practice it is unreasonable to expect mortality rates to drop to zero, despite our best efforts to understand, and, recognise treat the condition.  It is hoped that positive advancements, such as the recent World Health Assembly and WHO resolution on sepsis, will raise awareness of sepsis as a global priority, and its prevention, recognition, and treatment will improve worldwide. In the United States, there are currently 1.7 million cases of sepsis per year, a trend that has been increasing annually. \"\n",
    "# sentence = \"Exodus\"\n",
    "# sentence = \"Exodus\"\n",
    "input_sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\n",
    "last_embeddings = []\n",
    "\n",
    "token_embeddings = get_embeddings(input_sentence)\n",
    "\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "for token_emb in token_embeddings:\n",
    "#     print('w')\n",
    "    last_embedding_layer = token_emb[12]\n",
    "    last_embeddings.append(last_embedding_layer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "aux_array = []\n",
    "for last_embedding in last_embeddings:\n",
    "    aux_array.append(last_embedding.numpy())\n",
    "X_sentence = np.array(aux_array)\n",
    "len(X_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exodus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../models/biobert/vocab.txt', \"r\") as f:\n",
    "    labels = f.readlines()\n",
    "print(labels[23451])\n",
    "    \n",
    "md = torch.load('../models/biobert/pytorch_model.bin',map_location='cpu')\n",
    "for k in md:\n",
    "    if (k == 'bert.embeddings.word_embeddings.weight'):\n",
    "        embeds = md[k]\n",
    "# print(embeds[23451])\n",
    "\n",
    "token_isolado = np.array(embeds[23451])\n",
    "token_isolado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min \n",
    "result = pairwise_distances_argmin_min([token_isolado], clusters_centroids, metric=\"euclidean\")\n",
    "result\n",
    "print(original_clusters_centroids[246])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=1)\n",
    "kmeans.fit(X_sentence[1:2,:])\n",
    "\n",
    "sentence_centroid = kmeans.cluster_centers_\n",
    "\n",
    "result = pairwise_distances_argmin_min(sentence_centroid, clusters_centroids, metric=\"euclidean\")\n",
    "\n",
    "print(original_clusters_centroids[int(result[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_reduzido' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e67bfe9c6290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpectralEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reduzido\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_reduzido' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X_reduzido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(X_red, clustering.labels_, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(model, truncate_mode='level', p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(model.labels_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
