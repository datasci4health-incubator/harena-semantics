{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accomplished-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing impPredicort List\n",
    "\n",
    "def get_labels(path: str) -> List[str]:\n",
    "    if path:\n",
    "        with open(path, \"r\") as f:\n",
    "            labels = f.read().splitlines()\n",
    "            labels = [i+'-bio' if i != 'O' else 'O' for i in labels]\n",
    "        if \"O\" not in labels:\n",
    "            labels = [\"O\"] + labels\n",
    "        return labels\n",
    "    else:\n",
    "        # return [\"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]\n",
    "        return [\"O\", \"B-bio\", \"I-bio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "previous-beauty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-bio', 'I-bio', 'O']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = '../../datasets/NER/'\n",
    "ENTITY = 'NCBI-disease/'\n",
    "\n",
    "labels = get_labels(DATA_DIR + ENTITY + 'labels.txt')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "liable-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'I', 'O']\n",
      "{'O': 0, 'I': 1, 'B': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(DATA_DIR + ENTITY + 'train.tsv', delimiter='\\t', names=['word', 'label'], quoting=3, error_bad_lines=False)\n",
    "# train\n",
    "\n",
    "tag_values = list(set(train[\"label\"].values))\n",
    "tag_values\n",
    "# tag_values.append(\"PAD\")\n",
    "print(sorted(tag_values))\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "silver-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = 'biobert'\n",
    "MODEL = 'biobert_base_NER_NCBI-disease'\n",
    "\n",
    "MODEL_PATH = '../../models/word_embeddings/'\n",
    "# MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/models/' \n",
    "\n",
    "MODEL_PATH += MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-prophet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "attractive-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH, do_lower_case=False)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "curious-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 2\n",
      "Her 2\n",
      "eye 2\n",
      "is 2\n",
      "green 2\n",
      ". 2\n",
      "A 2\n",
      "58 2\n",
      "- 2\n",
      "year 2\n",
      "- 2\n",
      "old 2\n",
      "African 2\n",
      "- 2\n",
      "American 2\n",
      "woman 2\n",
      "presents 2\n",
      "to 2\n",
      "the 2\n",
      "ER 2\n",
      "with 2\n",
      "e 2\n",
      "##pis 2\n",
      "##od 2\n",
      "##ic 2\n",
      "pressing 1\n",
      "/ 2\n",
      "burning 0\n",
      "anterior 1\n",
      "chest 1\n",
      "pain 1\n",
      "that 2\n",
      "began 2\n",
      "two 2\n",
      "days 2\n",
      "earlier 2\n",
      "for 2\n",
      "the 2\n",
      "first 2\n",
      "time 2\n",
      "in 2\n",
      "her 2\n",
      "life 2\n",
      ". 2\n",
      "The 2\n",
      "pain 2\n",
      "started 2\n",
      "while 2\n",
      "she 2\n",
      "was 2\n",
      "walking 2\n",
      ", 2\n",
      "r 2\n",
      "##adia 2\n",
      "##tes 2\n",
      "to 2\n",
      "the 2\n",
      "eyes 2\n",
      ", 2\n",
      "and 2\n",
      "is 2\n",
      "accompanied 2\n",
      "by 2\n",
      "nausea 0\n",
      ", 2\n",
      "di 0\n",
      "##aph 0\n",
      "##ores 1\n",
      "##is 1\n",
      "and 2\n",
      "mild 2\n",
      "d 0\n",
      "##ys 1\n",
      "##p 1\n",
      "##nea 1\n",
      ", 2\n",
      "but 2\n",
      "is 2\n",
      "not 2\n",
      "increased 2\n",
      "on 2\n",
      "inspiration 2\n",
      ". 2\n",
      "The 2\n",
      "latest 2\n",
      "episode 2\n",
      "of 2\n",
      "pain 2\n",
      "ended 2\n",
      "half 2\n",
      "an 2\n",
      "hour 2\n",
      "prior 2\n",
      "to 2\n",
      "her 2\n",
      "arrival 2\n",
      ". 2\n",
      "She 2\n",
      "is 2\n",
      "known 2\n",
      "to 2\n",
      "have 2\n",
      "h 0\n",
      "##yper 1\n",
      "##tens 1\n",
      "##ion 1\n",
      "and 2\n",
      "o 0\n",
      "##besity 1\n",
      ". 2\n",
      "She 2\n",
      "denies 2\n",
      "smoking 2\n",
      ", 2\n",
      "diabetes 0\n",
      ", 2\n",
      "h 0\n",
      "##yper 0\n",
      "##cho 1\n",
      "##les 1\n",
      "##tero 1\n",
      "##lem 1\n",
      "##ia 1\n",
      ", 2\n",
      "or 2\n",
      "a 2\n",
      "family 2\n",
      "history 2\n",
      "of 2\n",
      "heart 0\n",
      "disease 1\n",
      ". 2\n",
      "She 2\n",
      "currently 2\n",
      "takes 2\n",
      "no 2\n",
      "medications 2\n",
      ". 2\n",
      "Physical 2\n",
      "examination 2\n",
      "is 2\n",
      "normal 2\n",
      ". 2\n",
      "The 2\n",
      "E 2\n",
      "##K 2\n",
      "##G 2\n",
      "shows 2\n",
      "non 2\n",
      "##sp 2\n",
      "##ec 2\n",
      "##ific 2\n",
      "changes 2\n",
      ". 2\n",
      "Al 2\n",
      "##pra 2\n",
      "##zo 2\n",
      "##lan 2\n",
      "was 2\n",
      "ad 2\n",
      "##mini 2\n",
      "##st 2\n",
      "##red 2\n",
      ". 2\n",
      "[SEP] 2\n",
      "B\t\t[CLS]\n",
      "B\t\tHer\n",
      "B\t\teye\n",
      "B\t\tis\n",
      "B\t\tgreen\n",
      "B\t\t.\n",
      "B\t\tA\n",
      "B\t\t58\n",
      "B\t\t-\n",
      "B\t\tyear\n",
      "B\t\t-\n",
      "B\t\told\n",
      "B\t\tAfrican\n",
      "B\t\t-\n",
      "B\t\tAmerican\n",
      "B\t\twoman\n",
      "B\t\tpresents\n",
      "B\t\tto\n",
      "B\t\tthe\n",
      "B\t\tER\n",
      "B\t\twith\n",
      "B\t\tepisodic\n",
      "I\t\tpressing\n",
      "B\t\t/\n",
      "O\t\tburning\n",
      "I\t\tanterior\n",
      "I\t\tchest\n",
      "I\t\tpain\n",
      "B\t\tthat\n",
      "B\t\tbegan\n",
      "B\t\ttwo\n",
      "B\t\tdays\n",
      "B\t\tearlier\n",
      "B\t\tfor\n",
      "B\t\tthe\n",
      "B\t\tfirst\n",
      "B\t\ttime\n",
      "B\t\tin\n",
      "B\t\ther\n",
      "B\t\tlife\n",
      "B\t\t.\n",
      "B\t\tThe\n",
      "B\t\tpain\n",
      "B\t\tstarted\n",
      "B\t\twhile\n",
      "B\t\tshe\n",
      "B\t\twas\n",
      "B\t\twalking\n",
      "B\t\t,\n",
      "B\t\tradiates\n",
      "B\t\tto\n",
      "B\t\tthe\n",
      "B\t\teyes\n",
      "B\t\t,\n",
      "B\t\tand\n",
      "B\t\tis\n",
      "B\t\taccompanied\n",
      "B\t\tby\n",
      "O\t\tnausea\n",
      "B\t\t,\n",
      "O\t\tdiaphoresis\n",
      "B\t\tand\n",
      "B\t\tmild\n",
      "O\t\tdyspnea\n",
      "B\t\t,\n",
      "B\t\tbut\n",
      "B\t\tis\n",
      "B\t\tnot\n",
      "B\t\tincreased\n",
      "B\t\ton\n",
      "B\t\tinspiration\n",
      "B\t\t.\n",
      "B\t\tThe\n",
      "B\t\tlatest\n",
      "B\t\tepisode\n",
      "B\t\tof\n",
      "B\t\tpain\n",
      "B\t\tended\n",
      "B\t\thalf\n",
      "B\t\tan\n",
      "B\t\thour\n",
      "B\t\tprior\n",
      "B\t\tto\n",
      "B\t\ther\n",
      "B\t\tarrival\n",
      "B\t\t.\n",
      "B\t\tShe\n",
      "B\t\tis\n",
      "B\t\tknown\n",
      "B\t\tto\n",
      "B\t\thave\n",
      "O\t\thypertension\n",
      "B\t\tand\n",
      "O\t\tobesity\n",
      "B\t\t.\n",
      "B\t\tShe\n",
      "B\t\tdenies\n",
      "B\t\tsmoking\n",
      "B\t\t,\n",
      "O\t\tdiabetes\n",
      "B\t\t,\n",
      "O\t\thypercholesterolemia\n",
      "B\t\t,\n",
      "B\t\tor\n",
      "B\t\ta\n",
      "B\t\tfamily\n",
      "B\t\thistory\n",
      "B\t\tof\n",
      "O\t\theart\n",
      "I\t\tdisease\n",
      "B\t\t.\n",
      "B\t\tShe\n",
      "B\t\tcurrently\n",
      "B\t\ttakes\n",
      "B\t\tno\n",
      "B\t\tmedications\n",
      "B\t\t.\n",
      "B\t\tPhysical\n",
      "B\t\texamination\n",
      "B\t\tis\n",
      "B\t\tnormal\n",
      "B\t\t.\n",
      "B\t\tThe\n",
      "B\t\tEKG\n",
      "B\t\tshows\n",
      "B\t\tnonspecific\n",
      "B\t\tchanges\n",
      "B\t\t.\n",
      "B\t\tAlprazolan\n",
      "B\t\twas\n",
      "B\t\tadministred\n",
      "B\t\t.\n",
      "B\t\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "test_sentence = 'Doctor, I am feeling chest pain since yesterday. The pain is continuous and is located just in the middle of my chest, worsening when I breathe and when I lay down on my bed. I suffer from arterial hypertension and smoke 20 cigarettes every day. My father had a “heart attack” at my age and I am very worried about it.'\n",
    "test_sentence = \" Her eye is green. A 58-year-old African-American woman presents to the ER with episodic pressing/burning anterior chest pain that began two days earlier for the first time in her life. The pain started while she was walking, radiates to the eyes, and is accompanied by nausea, diaphoresis and mild dyspnea, but is not increased on inspiration. The latest episode of pain ended half an hour prior to her arrival. She is known to have hypertension and obesity. She denies smoking, diabetes, hypercholesterolemia, or a family history of heart disease. She currently takes no medications. Physical examination is normal. The EKG shows nonspecific changes. Alprazolan was administred.\"\n",
    "\n",
    "tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "# input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "input_ids = torch.tensor([tokenized_sentence])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "# print(output)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "# join bpe split tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    print(token, label_idx)\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[label_idx])\n",
    "        new_tokens.append(token)\n",
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t\\t{}\".format(label, token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
